# NexAI ç‹¬ç«‹è„šæœ¬æ¼”ç¤º
# è¿è¡Œæ–¹å¼: mix run demo.exs

# 1. åŠ è½½ç¯å¢ƒå˜é‡
require Dotenvy
{:ok, env} = Dotenvy.source([".env", System.get_env()])
env |> Enum.each(fn {k, v} -> System.put_env(k, v) end)

IO.puts "ğŸ”§ å·²åŠ è½½é…ç½®:"
IO.puts "   - OpenAI Base URL: #{System.get_env("OPENAI_BASE_URL") || "é»˜è®¤"}"
IO.puts "   - Anthropic Base URL: #{System.get_env("ANTHROPIC_BASE_URL") || "é»˜è®¤"}"

alias NexAI.Message.User

IO.puts "\nğŸš€ [ç¤ºä¾‹ 1] åŸºç¡€ç”Ÿæˆ (generate_text) - ä½¿ç”¨ OpenAI"
IO.puts "---------------------------------------------------"

case NexAI.generate_text(
  model: NexAI.openai("gpt-4o"),
  messages: [%User{content: "ç”¨ä¸€å¥è¯æè¿° Elixir è¯­è¨€ã€‚"}]
) do
  {:ok, result} ->
    IO.puts "AI å›ç­”: #{result.text}"
    IO.puts "Token ç»Ÿè®¡: #{inspect(result.usage)}"
  {:error, reason} ->
    IO.puts "é”™è¯¯: #{inspect(reason)}"
end

IO.puts "\nğŸš€ [ç¤ºä¾‹ 2] æµå¼ç”Ÿæˆ (stream_text) - å®æ—¶æ‰“å° Token"
IO.puts "---------------------------------------------------"

case NexAI.stream_text(
  model: NexAI.openai("gpt-4o"),
  messages: [%User{content: "è¯·å†™ä¸€æ®µ 50 å­—å·¦å³çš„è¯—ã€‚"}]
) do
  {:error, err} -> 
    IO.puts "âŒ [æµéªŒè¯å¤±è´¥] #{inspect(err)}"
  result ->
    IO.write "AI æ­£åœ¨åˆ›ä½œ: "
    Enum.each(result.full_stream, fn event ->
      case event.type do
        :text -> 
          IO.write(event.payload)
        :error -> IO.puts "\n[æµé”™è¯¯] #{inspect(event.payload)}"
        :stream_finish -> IO.puts "\n[æµç»“æŸ] åŸå› : #{event.payload.finishReason}"
        _ -> :ok
      end
    end)
end

IO.puts "\nğŸš€ [ç¤ºä¾‹ 3] è‡ªåŠ¨å·¥å…·è°ƒç”¨ (Multi-step Tool Use)"
IO.puts "---------------------------------------------------"

weather_tool = NexAI.tool(%{
  name: "get_current_weather",
  description: "è·å–æŒ‡å®šåœ°ç‚¹çš„å¤©æ°”",
  parameters: %{
    type: "object",
    properties: %{
      location: %{type: "string", description: "åŸå¸‚åï¼Œå¦‚åŒ—äº¬"}
    },
    required: ["location"]
  },
  execute: fn %{"location" => loc} ->
    "#{loc}ç›®å‰å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸© 22Â°Cã€‚"
  end
})

IO.puts "æ‰§è¡Œä¸­ (å…è®¸ AI è‡ªåŠ¨è°ƒç”¨å·¥å…·å¹¶è·å–ç»“æœ)..."
{:ok, res} = NexAI.generate_text(
  model: NexAI.openai("gpt-4o"),
  tools: [weather_tool],
  max_steps: 5,
  messages: [%User{content: "æ·±åœ³çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿé€‚åˆç©¿ä»€ä¹ˆï¼Ÿ"}]
)

IO.puts "æœ€ç»ˆå›ç­”: #{res.text}"
IO.puts "ä¸­é—´æ­¥éª¤: #{length(res.steps)} æ­¥"

IO.puts "\nğŸš€ [ç¤ºä¾‹ 4] ä¸­é—´ä»¶ (Middleware) - æå–æ¨ç†è¿‡ç¨‹"
IO.puts "---------------------------------------------------"

smart_model = NexAI.Middleware.wrap_model(
  NexAI.openai("gpt-4o"),
  [{NexAI.Middleware.ExtractReasoning, tag: "thought"}]
)

{:ok, res} = NexAI.generate_text(
  model: smart_model,
  messages: [%User{content: "è¯·è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯èƒŒå‹ (Backpressure)ï¼Œå¹¶åœ¨å›ç­”å‰å…ˆåœ¨ <thought> æ ‡ç­¾å†…æ€è€ƒã€‚"}]
)

IO.puts "AI çš„æ€è€ƒè¿‡ç¨‹: #{res.reasoning || "æœªæ•è·åˆ°"}"
IO.puts "AI çš„æ­£å¼å›ç­”: #{res.text}"

IO.puts "\nğŸš€ [ç¤ºä¾‹ 5] æµå¼æ¨ç†æå– (Streaming Reasoning Extraction)"
IO.puts "---------------------------------------------------"

smart_model = NexAI.Middleware.wrap_model(
  NexAI.openai("gpt-4o"),
  [{NexAI.Middleware.ExtractReasoning, tag: "thought"}]
)

result = NexAI.stream_text(
  model: smart_model,
  messages: [%User{content: "ä¸ºä»€ä¹ˆå¤©ç©ºæ˜¯è“è‰²çš„ï¼Ÿè¯·åœ¨ <thought> ä¸­å…ˆæ€è€ƒã€‚"}]
)

IO.write "AI æ­£åœ¨æ€è€ƒå¹¶å›ç­”...\n"
Enum.each(result.full_stream, fn event ->
  case event.type do
    :reasoning -> 
      IO.write("\e[33m#{event.payload}\e[0m") # Yellow for reasoning
    :text -> 
      IO.write(event.payload)
    :error ->
      IO.puts "\nâŒ [æµé”™è¯¯] #{inspect(event.payload)}"
    _ -> :ok
  end
end)

IO.puts "\n\nâœ… æ‰€æœ‰æ¼”ç¤ºæ‰§è¡Œå®Œæ¯•ã€‚"
